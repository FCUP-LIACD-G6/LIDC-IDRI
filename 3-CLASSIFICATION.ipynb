{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c32368",
   "metadata": {},
   "source": [
    "## Neural Network approach\n",
    "\n",
    "-Realize the data is inbalanced\n",
    "\n",
    "-Testing an approach of eliminating all entries with label 3\n",
    "\n",
    "-Performing data split by patients, in train, test and val sets\n",
    "\n",
    "-Changing the labeling to binary classification\n",
    "\n",
    "-Implementing Random Forest to perform feature engineering, selecting the 75 best features\n",
    "\n",
    "-Defining, compiling and training and testing the NN model \n",
    "\n",
    "-Evaluating the model's performance \n",
    "\n",
    "-Trying SVM (with AdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f7f2d",
   "metadata": {},
   "source": [
    "### - Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bb10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c7f30c",
   "metadata": {},
   "source": [
    "### -Reading and defining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e48349",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading data\n",
    "\n",
    "data = pd.read_csv(\"D:/DATASET LIDC-IDRI/processeddata/features.csv\")\n",
    "data = data.dropna()\n",
    "data=data.drop(['diagnostics_Mask-original_CenterOfMass','diagnostics_Mask-original_CenterOfMassIndex','diagnostics_Versions_PyRadiomics','diagnostics_Versions_Numpy','diagnostics_Versions_SimpleITK','diagnostics_Versions_PyWavelet','diagnostics_Versions_Python','diagnostics_Configuration_Settings','diagnostics_Configuration_EnabledImageTypes','diagnostics_Image-original_Hash','diagnostics_Image-original_Dimensionality','diagnostics_Image-original_Spacing','diagnostics_Image-original_Size','diagnostics_Image-original_Mean','diagnostics_Image-original_Minimum','diagnostics_Image-original_Maximum','diagnostics_Mask-original_Hash','diagnostics_Mask-original_Spacing','diagnostics_Mask-original_Size','diagnostics_Mask-original_BoundingBox','diagnostics_Mask-original_VolumeNum','Sid','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5112e",
   "metadata": {},
   "source": [
    "### - Verifying class imbalance and erasing all entries with the label 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5c9d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4262\n",
       "2    3286\n",
       "5    2511\n",
       "4    2228\n",
       "1    2061\n",
       "Name: Malignancy, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Class inbalance??\n",
    "\n",
    "data[\"Malignancy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e689667",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Erasing entries with mal==3 (10082 left)\n",
    "i = data[data['Malignancy'] == 3].index\n",
    "data = data.drop(i)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed1f52",
   "metadata": {},
   "source": [
    "### -Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413426e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting patients into groups\n",
    "\n",
    "all_patients = data['Pid'].unique() #732 (if we remove mal=3)\n",
    "\n",
    "# Spliting patients into train, test and val groups\n",
    "train_patients, temp_patients = train_test_split(all_patients, test_size=0.3, random_state=42)\n",
    "test_patients, val_patients = train_test_split(temp_patients, test_size=0.5, random_state=42)\n",
    "\n",
    "# Creating the train, test and val datasets\n",
    "train_data = data[data['Pid'].isin(train_patients)]\n",
    "test_data = data[data['Pid'].isin(test_patients)]\n",
    "val_data = data[data['Pid'].isin(val_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d9aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "\n",
    "# Creating the train, test and val sets\n",
    "X_train = train_data.drop(['Pid','Malignancy'], axis=1)\n",
    "X_test = test_data.drop(['Pid','Malignancy'], axis=1)\n",
    "X_val = val_data.drop(['Pid','Malignancy'], axis=1)\n",
    "y_train = train_data['Malignancy']\n",
    "y_test = test_data['Malignancy']\n",
    "y_val = val_data['Malignancy']\n",
    "\n",
    "# Mapping malignancy levels to binary labels\n",
    "y_train = y_train.map({1: 0, 2: 0, 4: 1, 5: 1})\n",
    "y_test = y_test.map({1: 0, 2: 0, 4: 1, 5: 1})\n",
    "y_val = y_val.map({1: 0, 2: 0, 4: 1, 5: 1})\n",
    "\n",
    "# Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb9b77",
   "metadata": {},
   "source": [
    "### -Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3edb1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature engineering (Random Forest)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances from the trained Random Forest model\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Sort features based on their importance\n",
    "feature_indices = feature_importances.argsort()[::-1]  # Sort in descending order\n",
    "\n",
    "# Select the top K important features\n",
    "k = 75\n",
    "top_k_features_indices = feature_indices[:k]\n",
    "\n",
    "# Filter your data to keep only the selected features\n",
    "X_train_selected = X_train[:, top_k_features_indices]\n",
    "X_test_selected = X_test[:, top_k_features_indices]\n",
    "X_val_selected = X_val[:, top_k_features_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15802f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "## Apply the feature engineering\n",
    "\n",
    "X_train = X_train_selected\n",
    "X_test = X_test_selected\n",
    "X_val = X_val_selected\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f22e7c",
   "metadata": {},
   "source": [
    "### -Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f85d4be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "218/218 [==============================] - 2s 4ms/step - loss: 0.6580 - accuracy: 0.6309 - val_loss: 0.6061 - val_accuracy: 0.7073\n",
      "Epoch 2/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6514 - val_loss: 0.6085 - val_accuracy: 0.7114\n",
      "Epoch 3/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.6564 - val_loss: 0.6052 - val_accuracy: 0.7066\n",
      "Epoch 4/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6265 - accuracy: 0.6652 - val_loss: 0.6103 - val_accuracy: 0.7086\n",
      "Epoch 5/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6239 - accuracy: 0.6676 - val_loss: 0.6078 - val_accuracy: 0.7066\n",
      "Epoch 6/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6223 - accuracy: 0.6610 - val_loss: 0.6170 - val_accuracy: 0.7093\n",
      "Epoch 7/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6196 - accuracy: 0.6656 - val_loss: 0.6043 - val_accuracy: 0.7148\n",
      "Epoch 8/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.6698 - val_loss: 0.6041 - val_accuracy: 0.7046\n",
      "Epoch 9/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6141 - accuracy: 0.6751 - val_loss: 0.6150 - val_accuracy: 0.7086\n",
      "Epoch 10/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6156 - accuracy: 0.6712 - val_loss: 0.6155 - val_accuracy: 0.7066\n",
      "Epoch 11/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6120 - accuracy: 0.6744 - val_loss: 0.6299 - val_accuracy: 0.6984\n",
      "Epoch 12/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6121 - accuracy: 0.6768 - val_loss: 0.6251 - val_accuracy: 0.6978\n",
      "Epoch 13/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6070 - accuracy: 0.6767 - val_loss: 0.6224 - val_accuracy: 0.6984\n",
      "Epoch 14/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6065 - accuracy: 0.6741 - val_loss: 0.6276 - val_accuracy: 0.7059\n",
      "Epoch 15/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6020 - accuracy: 0.6800 - val_loss: 0.6275 - val_accuracy: 0.6889\n",
      "Epoch 16/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6048 - accuracy: 0.6814 - val_loss: 0.6344 - val_accuracy: 0.7100\n",
      "Epoch 17/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6055 - accuracy: 0.6782 - val_loss: 0.6288 - val_accuracy: 0.6991\n",
      "Epoch 18/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.6837 - val_loss: 0.6243 - val_accuracy: 0.6950\n",
      "Epoch 19/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6003 - accuracy: 0.6850 - val_loss: 0.6387 - val_accuracy: 0.6909\n",
      "Epoch 20/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.6007 - accuracy: 0.6831 - val_loss: 0.6372 - val_accuracy: 0.6930\n",
      "Epoch 21/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5977 - accuracy: 0.6814 - val_loss: 0.6404 - val_accuracy: 0.6950\n",
      "Epoch 22/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5969 - accuracy: 0.6818 - val_loss: 0.6513 - val_accuracy: 0.6978\n",
      "Epoch 23/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5956 - accuracy: 0.6893 - val_loss: 0.6469 - val_accuracy: 0.6943\n",
      "Epoch 24/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5971 - accuracy: 0.6798 - val_loss: 0.6362 - val_accuracy: 0.6950\n",
      "Epoch 25/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5911 - accuracy: 0.6873 - val_loss: 0.6443 - val_accuracy: 0.6848\n",
      "Epoch 26/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.6893 - val_loss: 0.6409 - val_accuracy: 0.6855\n",
      "Epoch 27/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5873 - accuracy: 0.6943 - val_loss: 0.6496 - val_accuracy: 0.6950\n",
      "Epoch 28/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5867 - accuracy: 0.6874 - val_loss: 0.6506 - val_accuracy: 0.6753\n",
      "Epoch 29/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5834 - accuracy: 0.6955 - val_loss: 0.6640 - val_accuracy: 0.6943\n",
      "Epoch 30/30\n",
      "218/218 [==============================] - 1s 3ms/step - loss: 0.5846 - accuracy: 0.6919 - val_loss: 0.6454 - val_accuracy: 0.6828\n"
     ]
    }
   ],
   "source": [
    "## NN aproach\n",
    "\n",
    "# Define the model\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.002), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8994bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.6380\n",
      "Test Accuracy: 0.64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsem 3: 0.62\\ncom 3=0: 0.68\\ncom 3=1: 0.62\\n\\nDecidimos explorar a opção sem 3\\n50 features ANOVA: 0.62\\n50 features RF: 0.63\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NN Results\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "'''\n",
    "sem 3: 0.62\n",
    "com 3=0: 0.68\n",
    "com 3=1: 0.62\n",
    "\n",
    "Decidimos explorar a opção sem 3\n",
    "50 features ANOVA: 0.62\n",
    "50 features RF: 0.63\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a79a2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-NN approach (Reused algorithms from ML1 project)\n",
    "\n",
    "# We decided to make that in a separate notebook since it did not perform the best\n",
    "# It was very coputationaly expensive to run, not worth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811b76c",
   "metadata": {},
   "source": [
    "### -SVM (with AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea93229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost with SVM base estimator on test set: 0.5997574287446937\n",
      "Accuracy of AdaBoost with SVM base estimator on validation set: 0.6977535738597685\n"
     ]
    }
   ],
   "source": [
    "## SVM approach (AdaBoost)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Assuming X_train_selected, X_test_selected, y_train, y_test are your selected features and labels\n",
    "\n",
    "# Initialize an SVM classifier (as the base estimator)\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost classifier using the SVM as the base estimator\n",
    "adaboost_clf = AdaBoostClassifier(base_estimator=svm_classifier, n_estimators=50, algorithm='SAMME', random_state=42)\n",
    "\n",
    "# Fit the AdaBoost classifier on the training data\n",
    "adaboost_clf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "accuracy = adaboost_clf.score(X_test_selected, y_test)\n",
    "print(f\"Accuracy of AdaBoost with SVM base estimator on test set: {accuracy}\")\n",
    "\n",
    "# Evaluate on validation data\n",
    "accuracy_val = adaboost_clf.score(X_val_selected, y_val)\n",
    "print(f\"Accuracy of AdaBoost with SVM base estimator on validation set: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f074e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
